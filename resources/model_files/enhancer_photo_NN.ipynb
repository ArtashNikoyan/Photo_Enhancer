{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEer5Rtqg3zg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipe40adLgxZf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, UpSampling2D, Concatenate\n",
        "import shutil\n",
        "import tempfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4WBYRLhEnP"
      },
      "source": [
        "## Params & Optimizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm8XBa7ChDAS"
      },
      "outputs": [],
      "source": [
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "PATCH_SIZE = 224\n",
        "PATCH_STRIDE = PATCH_SIZE // 2\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "MIN_VAR = 1e-6 \n",
        "MAX_PATCHES_PER_IMAGE = 6\n",
        "DATA_PATH = '/content/DATA'\n",
        "img_path = '/content/DATA/1812.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thHBlhainJsv"
      },
      "source": [
        "## Image degradation & load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPfgTEhJgYRV"
      },
      "outputs": [],
      "source": [
        "def degrade_tf(img_uint8):\n",
        "    \"\"\"\n",
        "    Applies random degradations (JPEG, brightness, contrast, noise) using TensorFlow.\n",
        "\n",
        "    Args:\n",
        "        img_uint8 (numpy.ndarray): Input image as a uint8 array.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Degraded image as a float32 array.\n",
        "    \"\"\"\n",
        "    img = tf.convert_to_tensor(img_uint8, dtype=tf.uint8)\n",
        "    # Apply random JPEG compression artifacts\n",
        "    img = tf.image.random_jpeg_quality(img, 20, 50)\n",
        "    # Randomly adjust brightness and contrast\n",
        "    img = tf.image.random_brightness(tf.cast(img, tf.float32), 0.15)\n",
        "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
        "    # Add additive Gaussian noise\n",
        "    noise = tf.random.normal(tf.shape(img), stddev=0.03 * 255.0)\n",
        "    img = img + noise\n",
        "    # Ensure pixel values stay within [0, 255] range\n",
        "    img = tf.clip_by_value(img, 0.0, 255.0)\n",
        "    return img.numpy().astype(np.float32)\n",
        "\n",
        "def load_img(path):\n",
        "    \"\"\"\n",
        "    Loads and decodes an image from a file path.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Decoded image tensor with 3 color channels.\n",
        "    \"\"\"\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO4VzQ0NnXZE"
      },
      "source": [
        "## Patch extraction/merge and padding/unpadding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-l2u0yunWo9"
      },
      "outputs": [],
      "source": [
        "def extract_patches(img, patch_size=224, step=112):\n",
        "    \"\"\"\n",
        "    Splits an image into overlapping patches.\n",
        "\n",
        "    Args:\n",
        "        img (numpy.ndarray): Input image array.\n",
        "        patch_size (int): Dimensions of each square patch.\n",
        "        step (int): Stride for extraction.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (Array of patches, List of (y, x) coordinates, Original height, Original width).\n",
        "    \"\"\"\n",
        "    H, W, C = img.shape\n",
        "    patches = []\n",
        "    positions = []\n",
        "\n",
        "    y_poss = list(range(0, H - patch_size + 1, step))\n",
        "    if y_poss[-1] + patch_size < H:\n",
        "        y_poss.append(H - patch_size)\n",
        "\n",
        "    x_poss = list(range(0, W - patch_size + 1, step))\n",
        "    if x_poss[-1] + patch_size < W:\n",
        "        x_poss.append(W - patch_size)\n",
        "\n",
        "    for y in y_poss:\n",
        "        for x in x_poss:\n",
        "            patches.append(img[y:y+patch_size, x:x+patch_size])\n",
        "            positions.append((y, x))\n",
        "\n",
        "    return np.array(patches), positions, H, W\n",
        "\n",
        "def get_weight_map(patch_size, eps=0.05):\n",
        "    \"\"\"\n",
        "    Creates a 2D Hanning window map for smooth patch blending.\n",
        "\n",
        "    Args:\n",
        "        patch_size (int): Size of the patch side.\n",
        "        eps (float): Minimum weight threshold.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: 2D weight map array.\n",
        "    \"\"\"\n",
        "    w = np.hanning(patch_size)\n",
        "    w = np.maximum(w, eps)\n",
        "    w2d = np.outer(w, w)\n",
        "    return w2d[..., None]\n",
        "\n",
        "def merge_patches(patches, positions, H, W, patch_size):\n",
        "    \"\"\"\n",
        "    Reconstructs an image from patches using weighted averaging.\n",
        "\n",
        "    Args:\n",
        "        patches (numpy.ndarray): Array of patches.\n",
        "        positions (list): Coordinates for each patch.\n",
        "        H (int): Target height.\n",
        "        W (int): Target width.\n",
        "        patch_size (int): Size of the patches.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Merged image as uint8.\n",
        "    \"\"\"\n",
        "    C = patches[0].shape[2]\n",
        "    output = np.zeros((H, W, C), dtype=np.float32)\n",
        "    weight = np.zeros((H, W, 1), dtype=np.float32)\n",
        "    weight_map = get_weight_map(patch_size)\n",
        "\n",
        "    for patch, (y, x) in zip(patches, positions):\n",
        "        output[y:y+patch_size, x:x+patch_size] += patch * weight_map\n",
        "        weight[y:y+patch_size, x:x+patch_size] += weight_map\n",
        "\n",
        "    output /= np.maximum(weight, 1e-6)\n",
        "    output = np.clip(output, 0, 255)\n",
        "    return output.astype(np.uint8)\n",
        "\n",
        "def pad_to_square(img, patch_size, pad_mode=\"reflect\"):\n",
        "    \"\"\"\n",
        "    Pads image to a square with dimensions divisible by patch_size.\n",
        "\n",
        "    Args:\n",
        "        img (numpy.ndarray): Input image.\n",
        "        patch_size (int): Size requirement for dimensions.\n",
        "        pad_mode (str): Padding strategy.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (Padded image, dict containing padding metadata).\n",
        "    \"\"\"\n",
        "    if img.ndim != 3:\n",
        "        raise ValueError(f\"Expected (H, W, C), got {img.shape}\")\n",
        "\n",
        "    h, w, c = img.shape\n",
        "    side = max(h, w)\n",
        "    target = ((side + patch_size - 1) // patch_size) * patch_size\n",
        "\n",
        "    pad_h = target - h\n",
        "    pad_w = target - w\n",
        "\n",
        "    top = pad_h // 2\n",
        "    bottom = pad_h - top\n",
        "    left = pad_w // 2\n",
        "    right = pad_w - left\n",
        "\n",
        "    padded = np.pad(img, ((top, bottom), (left, right), (0, 0)), mode=pad_mode)\n",
        "    pad_info = {\"top\": top, \"bottom\": bottom, \"left\": left, \"right\": right, \"orig_shape\": (h, w)}\n",
        "\n",
        "    return padded, pad_info\n",
        "\n",
        "def unpad_image(img, pad_info):\n",
        "    \"\"\"\n",
        "    Removes padding using previously saved metadata.\n",
        "\n",
        "    Args:\n",
        "        img (numpy.ndarray): Padded image.\n",
        "        pad_info (dict): Metadata with offsets and original shape.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Cropped original image.\n",
        "    \"\"\"\n",
        "    top = pad_info[\"top\"]\n",
        "    h, w = pad_info[\"orig_shape\"]\n",
        "    left = pad_info[\"left\"]\n",
        "    return img[top : top + h, left : left + w]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j483qTNcnjxn"
      },
      "source": [
        "## Dataset building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MlwlvhhsL5E"
      },
      "outputs": [],
      "source": [
        "all_paths = [os.path.join(DATA_PATH, f) for f in os.listdir(DATA_PATH)\n",
        "             if f.lower().endswith(('.jpg', '.png'))]\n",
        "random.shuffle(all_paths)\n",
        "split = int(0.8 * len(all_paths))\n",
        "train_paths = all_paths[:split]\n",
        "val_paths = all_paths[split:]\n",
        "\n",
        "def patch_generator(paths, patch_size=PATCH_SIZE, step=PATCH_STRIDE,\n",
        "                    max_patches_per_image=MAX_PATCHES_PER_IMAGE,\n",
        "                    min_var=MIN_VAR, identity_prob=0.2):\n",
        "    \"\"\"\n",
        "    Generator for training data (degraded patch vs original patch).\n",
        "    \n",
        "    Yields:\n",
        "        tuple: (Normalized input patch, Normalized target patch).\n",
        "    \"\"\"\n",
        "    for path in random.sample(paths, len(paths)):\n",
        "        img = cv2.imread(path)\n",
        "        if img is None: continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img, _ = pad_to_square(img, patch_size=patch_size)\n",
        "        patches, _, _, _ = extract_patches(img, patch_size=patch_size, step=step)\n",
        "        \n",
        "        idxs = list(range(len(patches)))\n",
        "        random.shuffle(idxs)\n",
        "        count = 0\n",
        "        for i in idxs:\n",
        "            patch = patches[i]\n",
        "            if patch.std() < min_var: continue\n",
        "            \n",
        "            target = patch.astype(np.float32) / 127.5 - 1.0\n",
        "            if random.random() < identity_prob:\n",
        "                input_patch = patch.copy()\n",
        "            else:\n",
        "                input_patch = degrade_tf(patch)\n",
        "            \n",
        "            input_patch = (np.clip(input_patch, 0, 255) / 127.5 - 1.0).astype(np.float32)\n",
        "            yield input_patch, target\n",
        "            \n",
        "            count += 1\n",
        "            if count >= max_patches_per_image: break\n",
        "\n",
        "def val_patch_generator(paths, patch_size=PATCH_SIZE, step=PATCH_STRIDE, min_var=MIN_VAR):\n",
        "    \"\"\"\n",
        "    Generator for validation data. Always applies degradation.\n",
        "\n",
        "    Yields:\n",
        "        tuple: (Normalized input patch, Normalized target patch).\n",
        "    \"\"\"\n",
        "    for path in paths:\n",
        "        img = cv2.imread(path)\n",
        "        if img is None: continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img, _ = pad_to_square(img, patch_size=patch_size)\n",
        "        patches, _, _, _ = extract_patches(img, patch_size=patch_size, step=step)\n",
        "\n",
        "        for patch in patches:\n",
        "            if patch.std() < min_var: continue\n",
        "            target = patch.astype(np.float32) / 127.5 - 1.0\n",
        "            input_patch = (np.clip(degrade_tf(patch), 0, 255) / 127.5 - 1.0).astype(np.float32)\n",
        "            yield input_patch, target\n",
        "\n",
        "# Build TF Datasets\n",
        "train_ds = tf.data.Dataset.from_generator(\n",
        "    lambda: patch_generator(train_paths),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec((PATCH_SIZE, PATCH_SIZE, 3), tf.float32),\n",
        "        tf.TensorSpec((PATCH_SIZE, PATCH_SIZE, 3), tf.float32)\n",
        "    )\n",
        ").shuffle(500).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_generator(\n",
        "    lambda: val_patch_generator(val_paths),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec((PATCH_SIZE, PATCH_SIZE, 3), tf.float32),\n",
        "        tf.TensorSpec((PATCH_SIZE, PATCH_SIZE, 3), tf.float32)\n",
        "    )\n",
        ").batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tymNkAedltU7"
      },
      "outputs": [],
      "source": [
        "plt.imshow(load_img(img_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "# --- Encoder ---\n",
        "# Block 1: 224 -> 112\n",
        "x = layers.Conv2D(16, 3, padding='same')(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(16, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "skip1 = x\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# Block 2: 112 -> 56\n",
        "x = layers.Conv2D(32, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(32, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "skip2 = x\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Block 3: 56 -> 28\n",
        "x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "skip3 = x\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "# Block 4: 28 -> 14\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "skip4 = x\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# --- Bottleneck ---\n",
        "x = layers.Conv2D(256, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(256, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# --- Decoder ---\n",
        "# Block 4 Up: 14 -> 28\n",
        "x = layers.UpSampling2D(2)(x)\n",
        "x = layers.Concatenate()([x, skip4])\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Block 3 Up: 28 -> 56\n",
        "x = layers.UpSampling2D(2)(x)\n",
        "x = layers.Concatenate()([x, skip3])\n",
        "x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "# Block 2 Up: 56 -> 112\n",
        "x = layers.UpSampling2D(2)(x)\n",
        "x = layers.Concatenate()([x, skip2])\n",
        "x = layers.Conv2D(32, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(32, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Block 1 Up: 112 -> 224\n",
        "x = layers.UpSampling2D(2)(x)\n",
        "x = layers.Concatenate()([x, skip1])\n",
        "x = layers.Conv2D(16, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Conv2D(16, 3, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# Final Layer\n",
        "outputs = layers.Conv2D(3, 1, activation='tanh', padding='same')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a mse_mae loss function\n",
        "\n",
        "# ===============================================================\n",
        "# LOSS FUNCTIONS AND EVALUATION METRICS\n",
        "# ===============================================================\n",
        "\n",
        "def mae_mse_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Combined Loss function using Mean Absolute Error (MAE) and Mean Squared Error (MSE).\n",
        "    \n",
        "    Weights are set to 60% MAE and 40% MSE to balance pixel-wise accuracy \n",
        "    and outlier penalization.\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted (enhanced) image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Weighted loss value.\n",
        "    \"\"\"\n",
        "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    return 0.6 * mae + 0.4 * mse\n",
        "\n",
        "def psnr_metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Peak Signal-to-Noise Ratio (PSNR) metric.\n",
        "    \n",
        "    Measures the quality of reconstruction. Higher values indicate better quality.\n",
        "    Note: max_val is 2.0 because data is normalized in range [-1, 1].\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: PSNR value in decibels.\n",
        "    \"\"\"\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=2.0)\n",
        "\n",
        "def ssim_metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Structural Similarity Index (SSIM) metric.\n",
        "    \n",
        "    Evaluates visual similarity based on luminance, contrast, and structure.\n",
        "    Note: max_val is 2.0 because data is normalized in range [-1, 1].\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: SSIM value (range -1 to 1, where 1 is identical).\n",
        "    \"\"\"\n",
        "    return tf.image.ssim(y_true, y_pred, max_val=2.0)\n",
        "\n",
        "# Optimizer setup with AdamW (Adam with Weight Decay)\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Compile model using the custom hybrid loss and metrics\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=mae_mse_loss,\n",
        "    metrics=[\n",
        "        tf.keras.metrics.MeanSquaredError(name='mse'),\n",
        "        psnr_metric,\n",
        "        ssim_metric\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ===============================================================\n",
        "# TRAINING PIPELINE\n",
        "# ===============================================================\n",
        "\n",
        "# Define training monitoring and adjustment callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model.keras',\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        factor=0.5,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Execute model training\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a edge loss function\n",
        "\n",
        "# ===============================================================\n",
        "# PERFORMANCE METRICS\n",
        "# ===============================================================\n",
        "\n",
        "def psnr_metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes the Peak Signal-to-Noise Ratio (PSNR) between images.\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: PSNR value based on a max value of 2.0 (range [-1, 1]).\n",
        "    \"\"\"\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=2.0)\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# PRIMARY LOSS FUNCTIONS\n",
        "# ===============================================================\n",
        "\n",
        "@tf.function\n",
        "def mae_mse_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Hybrid loss combining Mean Absolute Error and Mean Squared Error.\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Weighted loss (60% MAE + 40% MSE).\n",
        "    \"\"\"\n",
        "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    return 0.6 * mae + 0.4 * mse\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# EDGE-AWARE LOSS COMPONENTS\n",
        "# ===============================================================\n",
        "\n",
        "@tf.function\n",
        "def luminance(x):\n",
        "    \"\"\"\n",
        "    Converts an RGB image to grayscale luminance using standard coefficients.\n",
        "\n",
        "    Args:\n",
        "        x (tf.Tensor): Input RGB tensor.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Grayscale luminance tensor.\n",
        "    \"\"\"\n",
        "    return 0.299 * x[..., 0:1] + 0.587 * x[..., 1:2] + 0.114 * x[..., 2:3]\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def edge_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes loss based on image edges using the Sobel operator.\n",
        "    Downsamples the image first to focus on significant structural edges.\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Mean Absolute Error between Sobel edge maps.\n",
        "    \"\"\"\n",
        "    # Downsample to reduce noise sensitivity\n",
        "    y_true_down = tf.nn.avg_pool2d(y_true, 4, 4, padding=\"SAME\")\n",
        "    y_pred_down = tf.nn.avg_pool2d(y_pred, 4, 4, padding=\"SAME\")\n",
        "\n",
        "    y_true_lum = luminance(y_true_down)\n",
        "    y_pred_lum = luminance(y_pred_down)\n",
        "\n",
        "    # Calculate Sobel edges\n",
        "    edge_true = tf.stop_gradient(tf.image.sobel_edges(y_true_lum))\n",
        "    edge_pred = tf.stop_gradient(tf.image.sobel_edges(y_pred_lum))\n",
        "\n",
        "    return tf.reduce_mean(tf.abs(edge_true - edge_pred))\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# LOSS CONTROL PARAMETERS\n",
        "# ===============================================================\n",
        "\n",
        "# Boolean flag to toggle edge loss calculation during training batches\n",
        "edge_enabled = tf.Variable(False, trainable=False)\n",
        "# Weight factor for the edge loss component\n",
        "edge_weight = tf.constant(0.15, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# COMPOSITE LOSS CALCULATION\n",
        "# ===============================================================\n",
        "\n",
        "def total_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the final loss by combining base loss and optional edge loss.\n",
        "\n",
        "    Args:\n",
        "        y_true (tf.Tensor): Ground truth image patches.\n",
        "        y_pred (tf.Tensor): Predicted image patches.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Sum of base loss and weighted edge loss if enabled.\n",
        "    \"\"\"\n",
        "    base = mae_mse_loss(y_true, y_pred)\n",
        "    edge = tf.cond(\n",
        "        edge_enabled,\n",
        "        lambda: \n",
        "        edge_loss(y_true, y_pred),\n",
        "        lambda: tf.constant(0.0, dtype=tf.float32)\n",
        "    )\n",
        "    return base + edge_weight * edge\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# TRAINING CALLBACKS\n",
        "# ===============================================================\n",
        "\n",
        "class EdgeScheduler(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Keras Callback to toggle Edge Loss calculation every N batches.\n",
        "    This helps balance structural learning without excessive computational overhead.\n",
        "    \"\"\"\n",
        "    def __init__(self, every_n_steps=4):\n",
        "        super().__init__()\n",
        "        self.every_n_steps = every_n_steps\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Executed at the start of every batch to update the edge_enabled flag.\"\"\"\n",
        "        edge_enabled.assign(batch % self.every_n_steps == 0)\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# MODEL COMPILATION\n",
        "# ===============================================================\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=total_loss,\n",
        "    metrics=[\n",
        "        tf.keras.metrics.MeanSquaredError(name=\"mse\"),\n",
        "        psnr_metric\n",
        "    ],\n",
        "    run_eagerly=False\n",
        ")\n",
        "\n",
        "# List of callbacks for monitoring and scheduled adjustments\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"best_model.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,\n",
        "        factor=0.5,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EdgeScheduler(every_n_steps=4)\n",
        "]\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# MODEL TRAINING\n",
        "# ===============================================================\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
